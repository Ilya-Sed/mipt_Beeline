{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import accelerate\n",
    "\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"Accelerate version:\", accelerate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "df = pd.read_excel(\"no_voice.xlsx\")\n",
    "\n",
    "# Загрузка токенайзера и модели BERT\n",
    "model_name = 'DeepPavlov/rubert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "dataset = Dataset.from_pandas(df[['human_markup', 'label']])\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['human_markup'], truncation=True, padding='max_length', max_length=256)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['human_markup'])\n",
    "\n",
    "# Установление форматов для PyTorch\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Каталог для сохранения результатов\n",
    "    num_train_epochs=3,              # Количество эпох обучения\n",
    "    per_device_train_batch_size=8,   # Размер батча на каждом устройстве\n",
    "    logging_dir='./logs',            # Каталог для логов\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Создание DataCollator для обработки батчей\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# Создание объекта Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # Модель для дообучения\n",
    "    args=training_args,                  # Аргументы обучения\n",
    "    train_dataset=tokenized_datasets,    # Датасет для обучения\n",
    "    data_collator=data_collator          # Объект для обработки батчей\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./fine_tuned_model')\n",
    "tokenizer.save_pretrained('./fine_tuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Загрузка модели и токенайзера\n",
    "model_name = './fine_tuned_model'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "df = pd.read_excel('no_voice.xlsx')\n",
    "df = df[['model_annotation', 'label']]\n",
    "\n",
    "# Функция для генерации эмбеддингов\n",
    "def generate_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=256)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        # Используем эмбеддинги из последнего скрытого слоя\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy())\n",
    "    return embeddings\n",
    "\n",
    "# Генерация эмбеддингов для текстов\n",
    "df['embeddings'] = generate_embeddings(df['model_annotation'])\n",
    "\n",
    "\n",
    "def calculate_cosine_distances(embeddings, reference_embeddings):\n",
    "    distances = cosine_distances(embeddings, reference_embeddings)\n",
    "    return distances.mean(axis=1)\n",
    "\n",
    "reference_embeddings = np.array(df[df['label'] == 0]['embeddings'].tolist())\n",
    "\n",
    "df['cosine_distance'] = calculate_cosine_distances(np.array(df['embeddings'].tolist()), reference_embeddings)\n",
    "\n",
    "embeddings = np.array(df['embeddings'].tolist())\n",
    "\n",
    "\n",
    "df['is_correct'] = df['label'] == 0\n",
    "\n",
    "X = embeddings\n",
    "y = df['is_correct'].astype(int)  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear', probability=True))\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "y_pred_prob = svm_model.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "\n",
    "df_test = df.iloc[X_test.index]\n",
    "df_test['predicted_is_correct'] = y_pred\n",
    "df_test['predicted_is_correct_prob'] = y_pred_prob\n",
    "\n",
    "\n",
    "print(\"Correct texts predicted:\", df_test[df_test['predicted_is_correct'] == 1])\n",
    "print(\"Incorrect texts predicted:\", df_test[df_test['predicted_is_correct'] == 0])\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"with_emeddings_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_with_correctness.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отфильтровать строки, где label = 1\n",
    "label_1_df = df[df['label'] == 1]\n",
    "average_cosine_distance_label_1 = label_1_df['cosine_distance'].mean()\n",
    "print(\"Для 1 : \", average_cosine_distance_label_1)\n",
    "\n",
    "# Отфильтровать строки, где label = 0\n",
    "label_0_df = df[df['label'] == 0]\n",
    "average_cosine_distance_label_0 = label_0_df['cosine_distance'].mean()\n",
    "print(\"Для 0 : \", average_cosine_distance_label_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countMetrics(df, threshhold):\n",
    "    condition1 = (df['cosine_distance'] <= threshhold) & (df['label'] == 0)\n",
    "    count_condition1 = len(df[condition1])\n",
    "\n",
    "    # Фильтрация строк, где расстояние больше 0.6 и label = 1\n",
    "    condition2 = (df['cosine_distance'] > threshhold) & (df['label'] == 1)\n",
    "    count_condition2 = len(df[condition2])\n",
    "\n",
    "    condition3 = (df['cosine_distance'] <= threshhold) & (df['label'] == 1)\n",
    "    count_condition3 = len(df[condition3])\n",
    "\n",
    "    condition4 = (df['cosine_distance'] > threshhold) & (df['label'] == 0)\n",
    "    count_condition4 = len(df[condition4])\n",
    "    precision = count_condition1 / (count_condition1 + count_condition3)\n",
    "    recall = count_condition1 / (count_condition1 + count_condition4)\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    Accuracy = (count_condition1 + count_condition2) / (count_condition1 + count_condition2 + count_condition3 + count_condition4)\n",
    "    print(\"For threshhold: \", threshhold)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"Accuracy: \", Accuracy)\n",
    "    print(\"F1: \", F1)\n",
    "    return (Accuracy, F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 0.5\n",
    "\n",
    "max_f1 = 0\n",
    "max_acc = 0\n",
    "th_for_max_f1 = 0\n",
    "th_for_max_acc = 0\n",
    "while th <= 0.65:\n",
    "    acc, f1 = countMetrics(df, th)\n",
    "    if acc > max_acc:\n",
    "        max_acc = acc\n",
    "        th_for_max_acc = th\n",
    "    if f1 > max_f1:\n",
    "        max_f1 = f1\n",
    "        th_for_max_f1 = th\n",
    "    th += 0.01\n",
    "    \n",
    "print(\"Top Accuracy: \", max_acc, \" for threshhold \", th_for_max_acc)\n",
    "print(\"Top F1: \", max_f1, \" for threshhold \", th_for_max_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countMetrics2(df, threshhold):\n",
    "    condition1 = (df['cosine_distance'] <= threshhold) & (df['label'] == 0)\n",
    "    count_condition1 = len(df[condition1])\n",
    "\n",
    "    condition2 = (df['cosine_distance'] > threshhold) & (df['label'] == 1)\n",
    "    count_condition2 = len(df[condition2])\n",
    "\n",
    "    condition3 = (df['cosine_distance'] <= threshhold) & (df['label'] == 1)\n",
    "    count_condition3 = len(df[condition3])\n",
    "\n",
    "    condition4 = (df['cosine_distance'] > threshhold) & (df['label'] == 0)\n",
    "    count_condition4 = len(df[condition4])\n",
    "    precision = count_condition1 / (count_condition1 + count_condition3)\n",
    "    recall = count_condition1 / (count_condition1 + count_condition4)\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    Accuracy = (count_condition1 + count_condition2) / (count_condition1 + count_condition2 + count_condition3 + count_condition4)\n",
    "    print(\"For threshhold: \", threshhold)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"Accuracy: \", Accuracy)\n",
    "    print(\"F1: \", F1)\n",
    "    return (Accuracy, F1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
