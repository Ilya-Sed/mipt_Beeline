# Проектный практикум - Задача Билайн
## Команда № 10
* !["Team leader"](https://img.shields.io/badge/Team%20leader-%D0%90%D0%BD%D0%B4%D1%80%D0%B5%D0%B9%20%D0%A5%D0%B0%D0%BB%D0%BE%D0%B2-blue
)
* !["ML developer"](https://img.shields.io/badge/%D0%9F%D1%80%D0%BE%D0%B5%D0%BA%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8-%D0%98%D0%BB%D1%8C%D1%8F%20%D0%A1%D1%82%D0%BE%D1%80%D0%BE%D0%B6%D0%B5%D0%B2-yellow
)
* !["ML developer"](https://img.shields.io/badge/%D0%9F%D0%BE%D0%B4%D0%B3%D0%BE%D1%82%D0%BE%D0%B2%D0%BA%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85-%D0%A1%D0%B5%D0%BC%D1%91%D0%BD%20%D0%A8%D1%83%D0%BB%D1%8C%D0%B3%D0%B0-hex
)
* !["ML developer"](https://img.shields.io/badge/%D0%9E%D1%86%D0%B5%D0%BD%D0%BA%D0%B0%20%D0%BA%D0%B0%D1%87%D0%B5%D1%81%D1%82%D0%B2%D0%B0-%D0%98%D0%BB%D1%8C%D1%8F%20%D0%A1%D0%B5%D0%B4%D0%B5%D0%BB%D1%8C%D0%BD%D0%B8%D0%BA%D0%BE%D0%B2-red
)
* !["ML developer"](https://img.shields.io/badge/%D0%9F%D0%BE%D0%B4%D0%B3%D0%BE%D1%82%D0%BE%D0%B2%D0%BA%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85-%D0%98%D0%BB%D1%8C%D1%8F%20%D0%91%D0%B5%D1%86%D1%83%D0%BA%D0%B5%D0%BB%D0%B8-pink
)
* !["ML developer"](https://img.shields.io/badge/%D0%9F%D1%80%D0%BE%D0%B5%D0%BA%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8-%D0%94%D0%BC%D0%B8%D1%82%D1%80%D0%B8%D0%B9%20%D0%93%D0%BE%D0%BB%D0%BE%D0%B2%D0%B0%D1%87%D0%B5%D0%B2-orange
)

## Актуальное состояние проекта - Завершен

[Ноутбук с решением](https://colab.research.google.com/drive/1qiDr5y_rkbx6SuKz-vBtnyWrhb02nyxf?usp=sharing)  
[Data and models](https://drive.google.com/drive/folders/1NfTfijOL3Yp5FsXJDdAxr7iwltzwHgvy)

## Вводные по проекту и описание задачи 
Задача заключается в решении задачи бинарной классификации: определения качественно или нет транскрибирован аудиофрагмент (считаем, что аудио фрагмент транскрибирован качественно, если псевдоразметка отличается от ручной разметки не более, чем в N пунктов показателя WER).  

Командам будет предоставлен датасет следующего формата:

| id аудио фрагмента | Псевдоразметка | Ручная разметка | Качество |
| ------------ | ------------ | ------------ | ------------ |
| uid | текст | текст | 0/1 |

В данном датасете транскрибация получена с помощью псевдоразметки, то есть использования некоторой обученной ранее нейронной сети для ASR задач. От подобной разметки не ожидается хорошего качества, так как оно ограничено качеством используемой нейронной сети для выполнения псевдоразметки. Для улучшения качества ASR важно обучать нейронную сеть на качественно транскрибированных аудио фрагментах. Возникает вопрос: как определить без выполнения разметки данных хорошо ли выполнена транскрибация или нет?

Целевая метрика - ROC-AUC

## Решаемая бизнес проблема
Разметка данных для обучения ASR алгоритма требует больших ресурсов, компания стремиться оптимизировать этот процесс. Одно из решений: использование автоматической разметки данных.
Здесь возникает проблема: OpenSource решение (тоже модель ASR обученная на русском языке) выдает ошибки.
Требуется создать модель, которая будет распознавать ошибочные результаты работы авторазметки. То есть задачу можно определить как создание классификатора текстов (отличает валидный текст от невалидного).
По словам заказчика первый проход обычным классификатором "из коробки" дает ROC-AUC 60%, можно определить этот показатель как базовый (все что выше считается положительным результатом).

## Поиск решения:
Классификатор будет работать в условиях отсутствия валидного текста, написанного человеком и должен распознавать входящее строковое значение полученное от ASR модели с качесвом ROC-AUC выше 0.60, отличным результатом будет считаться 0.80.
Если модель не будет располагать текстом от человека, следовательно использовать данные от ручного распознавания в пространстве признаков неверно, однако эти данные являются ценными примерами "как правильно", на них можно проводить обучение модели.
ASR работает таким образом что отображает входящий закодированный аудиосигнал с определенным словом или токеном, но не определяет насколько вероятно или уместно это слово в контексте. Следовательно ошибки ASR будут семантическими (слова верные, но общий смысл фразы теряется). Значит классификатор должен оценивать семантическую значимость фразы. 
Семантическим представлением текстов обладают нейросети, через которые можно проводить токенизацию входящего текста. Например BERT или RoBERT, при этом для сохранения смысла сеть должна быть предобучена на русском языке плюс возможно провести дообучение такой сети на корпусе текстов от ручного набора (распознавания), тем самым делая сеть более специфичной к устной речи.
Далее получая вектор фиксированной длины мы можем оценить его близость с векторами "нормальных фраз" и провести классификацию. Это вариант 1.
Вариант 2 заключается в усложнении пайплайна и добавлении к эмбедингу дополнительных признаков (стекинг):
1) Вероятность классов SVM
2) Вероятность классов GB
3) Сумма вероятностей слов в каждой фразе, полученная через ту же дообученную BERT методом маскирования каждого слова по очереди
4) Разница вероятностей слов из пункта 3 с максимальной вероятностью слова которое предсказывает модель (тем самым мы можем оценить насколько фраза близка к "нормальной" речевой последовательности)

После составления расширенного набора признаков проводится классфикация методами классического ML или полносвязной нейросети.

# Реализованный пайплайн

1. Очищенные данные делим на test и train
2. Предобученную модель Bert дообучаем методом маскирования на разметке выполненной человеком, для понимания специфики употребляемой устной речи
3. Дополнительно дообучаем Bert, но уже на задачу классификации для определения вероятности классов
4. Составляем альтернативное представление признаков  
4.1 Маскируем случайное слово из фразы получаем предсказание и вероятность этого слова
4.2 И так далее пока не берем n-1 слов в последовательности N слов и вычисляем вероятность последнего слова
4.3 У нас получается вектор чисел вероятностей слов в данной фразе И вектор чисел вероятностей во фразе где каждое следующее слово предложено моделью
4.5 Далее надо отнять первый эелмент из первого вектора (первое слово), вектора стали одинаковой длины, поэлементно перемножить и сложить произведения Поэлементно вычесть второй вектор из первого и сложить результаты разницы
4.6 В результате получаем кортеж из двух чисел  
4.7 Используя этот аглоритм рассчитаем вероятности классов в обучающей и тестовой выборке  
4.8 Добавляем это признаковое описание к обучающей и тестовой выборке
5. Обучаем и примененяем BERT классификатор и LeNet
6. Обучаем и примененяем SVM, случайный лес и градиентный бустинг
7. Добавляем предсказания к признакам
8. Строим полносвязный классификатор на всех признаках
9. Считаем и оцениваем ROC-AUC

## Полученные результаты:

![result](https://thumb.cloud.mail.ru/weblink/thumb/xw1/vQCT/zBYmTf9fC)  
Лучшая полученная метрика ROC-AUC на тестовой выборке соствляет 0.76
