# Задача Билайн
!["time-leader"](https://img.shields.io/badge/%D0%9C%D0%B5%D0%BD%D0%B5%D0%B4%D0%B6%D0%B5%D1%80%20%D0%BF%D1%80%D0%BE%D0%B5%D0%BA%D1%82%D0%B0-%D0%90%D0%BD%D0%B4%D1%80%D0%B5%D0%B9%20%D0%9A%D1%85%D0%B0%D0%BB%D0%BE%D0%B2-blue
)
!["ML developer"](https://img.shields.io/badge/ML%20%D0%A0%D0%B0%D0%B7%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D1%87%D0%B8%D0%BA-%D0%94%D0%BC%D0%B8%D1%82%D1%80%D0%B8%D0%B9%20%D0%93%D0%BE%D0%BB%D0%BE%D0%B2%D0%B0%D1%87%D0%B5%D0%B2-orange
)
!["ML developer"](https://img.shields.io/badge/ML%20%D0%A0%D0%B0%D0%B7%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D1%87%D0%B8%D0%BA-%D0%98%D0%BB%D1%8C%D1%8F%20%D0%91%D0%B5%D1%86%D1%83%D0%BA%D0%B5%D0%BB%D0%B8-pink
)
!["ML developer"](https://img.shields.io/badge/ML_%D0%A0%D0%B0%D0%B7%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D1%87%D0%B8%D0%BA-%D0%98%D0%BB%D1%8C%D1%8F%20%D0%A1%D1%82%D0%BE%D1%80%D0%BE%D0%B6%D0%B5%D0%B2-yellow
)
!["ML developer"](https://img.shields.io/badge/%D0%A4%D1%83%D0%BB%D1%81%D1%82%D0%B5%D0%BA_%D0%A0%D0%B0%D0%B7%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D1%87%D0%B8%D0%BA-%D0%A1%D0%B5%D0%BC%D1%91%D0%BD_%D0%A8%D1%83%D0%BB%D1%8C%D0%B3%D0%B0-brightgreen
)
!["ML developer"](https://img.shields.io/badge/GitHub_%D0%9C%D0%B5%D0%BD%D0%B5%D0%B4%D0%B6%D0%B5%D1%80-%D0%98%D0%BB%D1%8C%D1%8F%20%D0%A1%D0%B5%D0%B4%D0%B5%D0%BB%D1%8C%D0%BD%D0%B8%D0%BA%D0%BE%D0%B2-red)

## Проблема
Разметка данных для обучения ASR алгоритма требует больших ресурсов, компания стремиться оптимизировать этот процесс. Одно из решений: использование автоматической разметки данных.
Здесь возникает проблема: OpenSource решение (тоже модель ASR обученная на русском языке) выдает ошибки.
Требуется создать модель, которая будет распознавать ошибочные результаты работы авторазметки. То есть задачу можно определить как создание классификатора текстов (отличает валидный текст от невалидного).
По словам заказчика первый проход обычным классификатором "из коробки" дает ROC-AUC 60%, можно определить этот показатель как базовый (все что выше считается положительным результатом).

Данные представляют собой таблицу с текстами от ASR, текстами написанными вручную, метку класса (1/0) и ссылку на аудиофрагмент речи.

## Вероятное решение: 
Основные рассуждения:
Классификатор будет работать в условиях отсутствия валидного текста, написанного человеком и должен распознавать входящее строковое значение полученное от ASR модели с качесвом ROC-AUC выше 0.60, отличным результатом будет считаться 0.80.
Если модель не будет располагать текстом от человека, следовательно использовать данные от ручного распознавания в пространстве признаков неверно, однако эти данные являются ценными примерами "как правильно", на них можно проводить обучение модели.
ASR работает таким образом что отображает входящий закодированный аудиосигнал с определенным словом или токеном, но не определяет насколько вероятно или уместно это слово в контексте. Следовательно ошибки ASR будут семантическими (слова верные, но общий смысл фразы теряется). Значит классификатор должен оценивать семантическую значимость фразы. 
Семантическим представлением текстов обладают нейросети, через которые можно проводить токенизацию входящего текста. Например BERT или RoBERT, при этом для сохранения смысла сеть должна быть предобучена на русском языке плюс возможно провести дообучение такой сети на корпусе текстов от ручного набора (распознавания), тем самым делая сеть более специфичной к устной речи.
Далее получая вектор фиксированной длины мы можем оценить его близость с векторами "нормальных фраз" и провести классификацию. Это вариант 1.
Вариант 2 заключается в усложнении пайплайна и добавлении к эмбедингу дополнительных признаков (стекинг):
1) Вероятность классов SVM
2) Вероятность классов GB
3) Сумма вероятностей слов в каждой фразе, полученная через ту же дообученную BERT методом маскирования каждого слова по очереди
4) Разница вероятностей слов из пункта 3 с максимальной вероятностью слова которое предсказывает модель (тем самым мы можем оценить насколько фраза близка к "нормальной" речевой последовательность

После составления расширенного набора признаков проводится классфикация методами классического ML или полносвязной нейросети.
  

## Промежуточные результаты:
На данный момент лучшая метрика ROC-AUC соствляет 0.725, на BERT дообученной в течении 5 эпох. Близкие результаты дает вариант 2.
Проводятся эксперименты по понижении размерности эмбединга методом главных компонент.
Ведутся работы по предсказанию вероятности слова через RNN, против метода маскирования.
Проводится обучения модели BERT и RoBERT в течении 20 эпох.

## Дальнейшие действия:
Эксперименты с дообученной моделью
Расширение пространства признаков
Применение сверточной нейросети для работы с эмбедингами и в качестве финального классификатора
Применение RNN для вычисления вероятности появления каждого слова в последовательности
Отрисовка графиков
Выводы


